{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-21T05:14:01.810406Z","iopub.execute_input":"2023-09-21T05:14:01.810931Z","iopub.status.idle":"2023-09-21T05:14:01.856054Z","shell.execute_reply.started":"2023-09-21T05:14:01.810896Z","shell.execute_reply":"2023-09-21T05:14:01.854873Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> 추가한 부분은 파란색 형광펜을 사용하여 표시하였다.  \n> 번역한 부분은 노란색 형광펜으로 나타내었다.  \n  \n>  20236500 홍사훈","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:53:37.119673Z","iopub.execute_input":"2023-09-23T08:53:37.120301Z","iopub.status.idle":"2023-09-23T08:53:37.148488Z","shell.execute_reply.started":"2023-09-23T08:53:37.120265Z","shell.execute_reply":"2023-09-23T08:53:37.147521Z"}}},{"cell_type":"markdown","source":"# Predicting the Age of Crabs: Enhancing Predictive Performance with Feature Engineering\n\nIn a previous notebook, we took a preliminary stab at predicting crab ages based on a set of basic biological and physical features. We used a dataset containing information on various aspects such as the crab's gender, body dimensions (length, diameter, height), weight (total, shucked, viscera, shell), and age. While we achieved a decent prediction accuracy with these basic features, there's potential for enhancement.\n\nPrevious Notebook - https://www.kaggle.com/code/pandeyg0811/mae-1-33-eda-ensemble","metadata":{}},{"cell_type":"markdown","source":"<span style=\"background-color:#fff5b1\">\n이전 노트북에서, 게의 나이를 추측할 수 있는 생물학적 지표를 살펴보았다. 길이, 무게 등 기본적 지표만으로도 괜찮은 성능을 낼 수 있었지만, 향상될 여지가 있다.\n</span>","metadata":{}},{"cell_type":"markdown","source":"## Introduction\n\nIn this notebook, we're delving deeper into the world of crustacean life-cycles, specifically crabs. Crabs are fascinating creatures with diverse biological characteristics, playing crucial roles in marine ecosystems. A key attribute that's often challenging to estimate but crucial for biological and ecological studies is the age of a crab. Understanding the age distribution of a crab population can significantly contribute to population dynamics, growth rates, lifecycle understanding, and conservation strategies.","metadata":{}},{"cell_type":"markdown","source":"<span style=\"background-color:#fff5b1\"> 이 노트북에서, 게의 일생에 대해 깊이 알아볼 것이다. 게의 나이 분포를 알아내는 것은 보존 전략 수립, 일생 주기 이해 등에 중요하다. </span>","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import gc\nimport math\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, roc_auc_score\nfrom sklearn.model_selection import train_test_split, cross_val_predict, KFold\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom catboost import CatBoostRegressor, Pool\nimport lightgbm as lgb\nimport xgboost as xgb\nimport optuna\n\nimport warnings\nwarnings.simplefilter(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-09-21T05:14:01.882336Z","iopub.execute_input":"2023-09-21T05:14:01.883087Z","iopub.status.idle":"2023-09-21T05:14:06.135762Z","shell.execute_reply.started":"2023-09-21T05:14:01.883056Z","shell.execute_reply":"2023-09-21T05:14:06.134480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"background-color:#C0FFFF\"> 라이브러리 임포트 </span>","metadata":{}},{"cell_type":"markdown","source":"# Importing Dataset","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/playground-series-s3e16/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/playground-series-s3e16/test.csv\")\ndf_original = pd.read_csv(\"/kaggle/input/crab-age-prediction/CrabAgePrediction.csv\")\n\ndf_train[\"Data Type\"] = 0\ndf_test[\"Data Type\"] = 1\ndf_original[\"Data Type\"] = 2\n\n\n# label encoding (feature \"Sex\" is categorical)\nle = LabelEncoder()\ndf_train[\"Sex\"] = le.fit_transform(df_train[\"Sex\"])\ndf_test[\"Sex\"] = le.transform(df_test[\"Sex\"])\ndf_original[\"Sex\"] = le.transform(df_original[\"Sex\"])\n\n# concatenate datasets\ndf_concat = pd.concat([df_train.drop('id',axis=1), df_original], ignore_index=True)\ndf_concat = df_concat.drop_duplicates()\ndf_all = pd.concat([df_concat, df_test.drop('id',axis=1)], ignore_index=True)\ndf_all","metadata":{"execution":{"iopub.status.busy":"2023-09-21T06:11:04.542725Z","iopub.execute_input":"2023-09-21T06:11:04.543253Z","iopub.status.idle":"2023-09-21T06:11:04.708273Z","shell.execute_reply.started":"2023-09-21T06:11:04.543205Z","shell.execute_reply":"2023-09-21T06:11:04.707066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"background-color:#C0FFFF\"> 데이터셋 df로 불러온 후, categorical value인 sex를 label encoding한다. 그후, id를 제거한 train, test df를 합친다.</span>","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:08:43.475838Z","iopub.execute_input":"2023-09-23T09:08:43.476253Z","iopub.status.idle":"2023-09-23T09:08:43.482724Z","shell.execute_reply.started":"2023-09-23T09:08:43.476219Z","shell.execute_reply":"2023-09-23T09:08:43.481532Z"}}},{"cell_type":"markdown","source":"## Imputing Height variable","metadata":{}},{"cell_type":"code","source":"# repalce some wrong data (Height=0) with random forest prediction\nh1 = df_all[df_all[\"Height\"] != 0]\nh0 = df_all[df_all[\"Height\"] == 0]\nprint(h1.shape, h0.shape)\n\nx_h1 = h1.drop(columns=[ \"Height\", \"Age\", \"Data Type\"], axis=1)\ny_h1 = h1[\"Height\"]\nx_h0 = h0.drop(columns=[ \"Height\", \"Age\", \"Data Type\"], axis=1)\n\nrfr = RandomForestRegressor(n_jobs=-1, random_state=28)\nrfr.fit(x_h1, y_h1)\npreds_height = rfr.predict(x_h0)\n\ncnt = 0\nfor i in range(len(df_all)):\n    if df_all.loc[i, \"Height\"] == 0:\n        df_all.loc[i, \"Height\"] = preds_height[cnt]\n        cnt += 1\n\ndf_all[\"Height\"].describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T06:11:07.286214Z","iopub.execute_input":"2023-09-21T06:11:07.286560Z","iopub.status.idle":"2023-09-21T06:12:04.759649Z","shell.execute_reply.started":"2023-09-21T06:11:07.286534Z","shell.execute_reply":"2023-09-21T06:12:04.758351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"background-color:#C0FFFF\"> height가 0인 행에 대해 그렇지 않은 행으로 RandomForest모델을 fit한 후 그 행들을 predict한다. </span>","metadata":{}},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"code","source":"lgb_params = {\n    \"objective\": \"regression_l1\", # =\"mae\"\n    \"metric\": \"mae\",\n    \"learning_rate\": 0.03, # 0.1\n    \"n_estimators\": 10000,\n    \"max_depth\": 8, # -1, 1-16(3-8)\n    \"num_leaves\": 255, # 31, 2-2**max_depth\n    \"feature_fraction\": 0.4, # 1.0, 0.1-1.0, 0.4\n    \"min_data_in_leaf\": 256, # 20, 0-300\n    \"subsample\": 0.4, # 1.0, 0.01-1.0\n    \"reg_alpha\": 0.1, # 0.0, 0.0-10.0, 0.1\n    \"reg_lambda\": 0.1, # 0.0, 0.0-10.0, 0.1\n    ###\"subsample_freq\": 0, # 0-10\n    ###\"max_bin\": 255, # 32-512\n    ###\"min_gain_to_split\": 0.0, # 0.0-15.0\n    ###\"subsample_for_bin\": 200000, # 30-len(x_train)\n    ###\"boosting\": \"dart\", # \"gbdt\"\n    ###\"device_type\": \"gpu\", # \"cpu\"\n}","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-21T05:14:25.729929Z","iopub.execute_input":"2023-09-21T05:14:25.730284Z","iopub.status.idle":"2023-09-21T05:14:25.736524Z","shell.execute_reply.started":"2023-09-21T05:14:25.730256Z","shell.execute_reply":"2023-09-21T05:14:25.735011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"background-color:#C0FFFF\"> lgb 모델에 쓸 parameter를 지정한다. 주석의 흔적으로 보아 이미 점수를 높이기 위해 파라미터 튜닝을 마쳤을 가능성이 높다. </span>","metadata":{}},{"cell_type":"markdown","source":"### Train and Test Data Split","metadata":{}},{"cell_type":"code","source":"train = df_all[df_all['Data Type'] != 1]\ntrain.reset_index(drop=True, inplace=True)\n\ny_train = train[\"Age\"].astype(int)\nx_train = train.drop(columns=[\"Age\", \"Data Type\"], axis=1)\n\nx_test = df_all[df_all[\"Data Type\"] == 1]\nx_test.reset_index(drop=True, inplace=True)\nx_test.drop(columns=[\"Age\", \"Data Type\"], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T05:14:25.738638Z","iopub.execute_input":"2023-09-21T05:14:25.739024Z","iopub.status.idle":"2023-09-21T05:14:25.765174Z","shell.execute_reply.started":"2023-09-21T05:14:25.738992Z","shell.execute_reply":"2023-09-21T05:14:25.763660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LightGBM Model","metadata":{}},{"cell_type":"code","source":"def LightGBM(X, y, test_data, params):\n    kf = list(KFold(n_splits=10, shuffle=True, random_state=100).split(X, y))\n    preds, models = [], []\n    oof = np.zeros(len(X))\n    imp = pd.DataFrame()\n    \n    for nfold in np.arange(10):\n        print(\"-\"*30, \"fold:\", nfold, \"-\"*30)\n        \n        # set train/valid data\n        idx_tr, idx_va = kf[nfold][0], kf[nfold][1]\n        x_tr, y_tr = X.loc[idx_tr, :], y.loc[idx_tr]\n        x_va, y_va = X.loc[idx_va, :], y.loc[idx_va]\n        \n        # training\n        model = lgb.LGBMRegressor(**params)\n        model.fit(x_tr, y_tr,\n                eval_set=[(x_tr, y_tr), (x_va, y_va)],\n                early_stopping_rounds=300,\n                verbose=500,\n        )\n        models.append(model)\n        \n        # validation\n        pred_va = model.predict(x_va)\n        oof[idx_va] = pred_va\n        print(\"MAE(valid)\", nfold, \":\", \"{:.4f}\".format(mean_absolute_error(y_va, pred_va)))\n        \n        # prediction\n        pred_test = model.predict(test_data)\n        preds.append(pred_test)\n        \n        # importance\n        _imp = pd.DataFrame({\"features\": X.columns, \"importance\": model.feature_importances_, \"nfold\": nfold})\n        imp = pd.concat([imp, _imp], axis=0, ignore_index=True)\n    \n    imp = imp.groupby(\"features\")[\"importance\"].agg([\"mean\", \"std\"])\n    imp.columns = [\"importance\", \"importance_std\"]\n    imp[\"importance_cov\"] = imp[\"importance_std\"] / imp[\"importance\"]\n    imp = imp.reset_index(drop=False)\n    display(imp.sort_values(\"importance\", ascending=False, ignore_index=True))\n    \n    return preds, models, oof, imp","metadata":{"execution":{"iopub.status.busy":"2023-09-21T05:14:25.767087Z","iopub.execute_input":"2023-09-21T05:14:25.767720Z","iopub.status.idle":"2023-09-21T05:14:25.778794Z","shell.execute_reply.started":"2023-09-21T05:14:25.767689Z","shell.execute_reply":"2023-09-21T05:14:25.777407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"background-color:#C0FFFF\"> fold를 10개로 나눠서 lgb 모델에 대해 교차검증을 수행하는 함수를 만든다.  \n각 fold의 mae를 구하고 각 feature의 importance를 출력한다.</span>","metadata":{}},{"cell_type":"markdown","source":"## Model without Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Training\npreds_lgb, models_lgb, oof_lgb, imp_lgb = LightGBM(x_train, y_train, x_test, lgb_params)\n\n# MAE for LightGBM\noof_lgb_round = np.zeros(len(oof_lgb), dtype=int)\nfor i in range(len(oof_lgb)):\n    oof_lgb_round[i] = int((oof_lgb[i] * 2 + 1) // 2)\n\nprint(\"MAE(int):\", \"{:.4f}\".format(mean_absolute_error(y_train, oof_lgb_round)))\nprint(\"MAE(float):\", \"{:.4f}\".format(mean_absolute_error(y_train, oof_lgb)))\n\n# visualization of predictions by test-data\nmean_preds_lgb = np.mean(preds_lgb, axis=0)\nmean_preds_lgb_round = np.zeros(len(mean_preds_lgb), dtype=int)\nfor i in range(len(mean_preds_lgb_round)):\n    mean_preds_lgb_round[i] = int((mean_preds_lgb[i] * 2 + 1) // 2)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T05:14:25.780391Z","iopub.execute_input":"2023-09-21T05:14:25.780701Z","iopub.status.idle":"2023-09-21T05:20:47.566014Z","shell.execute_reply.started":"2023-09-21T05:14:25.780673Z","shell.execute_reply":"2023-09-21T05:20:47.565039Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"background-color:#C0FFFF\"> 주어진 기본 데이터셋을 활용해 MAE를 구한다.  \n나이는 정수 값이므로 반올림한 값에 대한 MAE도 구한다.</span>","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:29:24.075757Z","iopub.execute_input":"2023-09-23T09:29:24.076510Z","iopub.status.idle":"2023-09-23T09:29:24.081643Z","shell.execute_reply.started":"2023-09-23T09:29:24.076480Z","shell.execute_reply":"2023-09-23T09:29:24.080715Z"}}},{"cell_type":"markdown","source":"# Reducing Error with with Feature Engineering\n\nNow, we are ready to take our analysis a step further. In this notebook, we're going to incorporate feature engineering - a powerful tool that allows us to create new features from existing ones, thereby injecting our domain knowledge into the models, enhancing the richness of our data, and potentially boosting the predictive performance of our models.\n\nFeature engineering is often what separates a good model from a great one. It can help us uncover complex patterns in the data that basic models might overlook. Given the intricacy of biological entities like crabs, there's a great deal of potential in engineering new features that better capture the nuanced aspects of a crab's biology and life history.\n\nWe'll be exploring a range of feature engineering techniques such as creating ratio features to capture relative size differences, geometric features to encapsulate physical properties, polynomial features to capture non-linear relationships, logarithmic transformations to manage extreme values, binning to simplify relationships with the target variable, and creating new weight-related features to provide a deeper look into weight distribution.\n\nBy the end of this notebook, we will have a much-improved model for predicting crab age, setting the stage for more accurate and informed biological and ecological studies. Let's dive in!","metadata":{}},{"cell_type":"markdown","source":"<span style=\"background-color:#fff5b1\"> 모델의 성능을 향상시켜 줄 feature engineering을 한다.  \n비율, 기하학적, 다항, 로그, binning 피처를 활용한다.</span>","metadata":{}},{"cell_type":"markdown","source":"\n### 1. Ratio-based features\n\n- **Viscera Ratio**: The proportion of the crab's weight that comes from the viscera. This might be useful in understanding how the internal organ development correlates with the crab's age. \n   * Formula: `Viscera Ratio = Viscera Weight / Weight`\n\n### 2. Geometric features\n\n- **Surface Area**: Surface area of the crab computed as if it were a box. This feature could encapsulate the crab's overall size in a different way that the individual dimensions do not capture.\n   * Formula: `Surface Area = 2 * (Length * Diameter + Length * Height + Diameter * Height)`\n- **Volume**: Volume of the crab computed as if it were a box. Similar to the surface area, this provides a holistic measure of the crab's size.\n   * Formula: `Volume = Length * Diameter * Height`\n- **Density**: Density of the crab computed based on its weight and volume. It might help understand if older crabs tend to be denser or lighter for their size.\n   * Formula: `Density = Weight / Volume`\n\n### 3. Weight-related features\n\n- **Shell-to-Body Ratio**: Ratio of the shell weight to the sum of total weight and shell weight. This can help understand if the shell development has a correlation with the crab's age.\n   * Formula: `Shell-to-Body Ratio = Shell Weight / (Weight + Shell Weight)`\n- **Meat Yield**: Ratio of the shucked weight to the sum of total weight and shell weight. It may capture if older crabs tend to have more or less meat relative to their total size.\n   * Formula: `Meat Yield = Shucked Weight / (Weight + Shell Weight)`\n- **Weight_wo_Viscera**: Weight of the crab without the viscera. It can help to examine how much of the crab's weight comes from non-viscera parts and if that changes with age.\n   * Formula: `Weight_wo_Viscera = Shucked Weight - Viscera Weight`\n\n### 4. Polynomial features\n\n- **Length^2**: Squared length of the crab. It might capture any non-linear relationships between length and age.\n   * Formula: `Length^2 = Length ** 2`\n- **Diameter^2**: Squared diameter of the crab. Similar to length squared, this might capture any non-linear relationships between diameter and age.\n   * Formula: `Diameter^2 = Diameter ** 2`\n\n### 5. Logarithmic transformations\n\n- **Log Weight**: Logarithm of the crab's weight. This might help deal with any extreme or skewed weight values and can sometimes help linearize relationships with the target variable.\n   * Formula: `Log Weight = log(Weight + 1)`\n\n### 6. Binning\n\n- **Length Bins**: Discretization of the length into 4 bins. This simplifies the relationship of length with age and helps deal with any irregularities or noise in the relationship.\n   * Formula: `Length Bins = pd.cut(Length, bins=4, labels=False)`","metadata":{}},{"cell_type":"markdown","source":"<span style=\"background-color:#C0FFFF\"> 피처 생성: </span>\n\n> 1. **내장 비율**: *(내장 무게) / (무게)*, 게의 나이에 따라 내장 무게의 비율이 달라짐을 캐치한다.  \n> 2. **표면적**: 높이, 가로 길이, 세로 길이를 활용하여 게를 직사각형의 큐브라 가정하고 표면적을 구한다.  \n> 3. **부피**: 표면적과 유사하게 부피를 구한다.  \n> 4. **밀도**: *(무게)/(부피)*\n> 5. **껍질 비율**: *(껍질 무게) / (껍질 무게 + 전체 무게)*, 게의 나이에 따라 껍질 무게의 변화를 캐치한다.  \n> 6. **살점 비율**: *(내부 무게) / (껍질 무게 + 전체 무게)*, 게의 나이에 따라 살점 무게의 변화를 캐치한다.  \n> 7. **내장을 제외한 무게**: *(내부 무게)-(내장 무게)* \n> 8. **(가로 길이)^2, (세로 길이)^2**: 나이와 가로 세로 길이 간의 다항적 관계를 캐치한다.\n> 9. **log(무게 + 1)**: 무게 피처의 skewness와 이상치에 의한 영향을 줄이고 로그적 관계를 캐치한다.\n> 10. **길이 bin**: 길이 데이터를 4개의 구간으로 나누어 1-4의 값을 부여한다. 길이와 나이 간 관계를 단순화하고 노이즈를 줄인다.\n\n<span style=\"background-color:#C0FFFF\"> score에 유의미한 피처만을 선별해 놓은 것으로 보인다. </span>","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:35:08.292094Z","iopub.execute_input":"2023-09-23T09:35:08.292474Z","iopub.status.idle":"2023-09-23T09:35:08.297957Z","shell.execute_reply.started":"2023-09-23T09:35:08.292444Z","shell.execute_reply":"2023-09-23T09:35:08.296996Z"}}},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"df_all[\"Viscera Ratio\"] = df_all[\"Viscera Weight\"] / df_all[\"Weight\"]\ndf_all[\"Shell Ratio\"] = df_all[\"Shell Weight\"] / df_all[\"Weight\"]\ndf_all[\"Surface Area\"] = 2 * (df_all[\"Length\"] * df_all[\"Diameter\"] + df_all[\"Length\"] * df_all[\"Height\"] + df_all[\"Diameter\"] * df_all[\"Height\"])\ndf_all[\"Volume\"] = df_all[\"Length\"] * df_all[\"Diameter\"] * df_all[\"Height\"]\ndf_all[\"Density\"] = df_all[\"Weight\"] / df_all[\"Volume\"]\ndf_all['Shell-to-Body Ratio'] = df_all['Shell Weight'] / (df_all['Weight'] + df_all['Shell Weight'])\ndf_all['Meat Yield'] = df_all['Shucked Weight'] / (df_all['Weight'] + df_all['Shell Weight'])\ndf_all['Body Condition Index'] = np.sqrt(df_all['Length'] * df_all['Weight'] * df_all['Shucked Weight'])\ndf_all['Pseudo BMI']=df_all['Weight']/(df_all['Height']**2)\ndf_all['Len-to-Diam']=df_all['Length']/df_all['Diameter']\ndf_all['wieght-to-Viswieght']=df_all['Weight']/df_all['Viscera Weight']\ndf_all['wieght-to-Shellwieght']=df_all['Weight']/df_all['Shell Weight']\ndf_all['wieght-to-Shckwieght']=df_all['Weight']/df_all['Shucked Weight']\ndf_all[\"Weight_wo_Viscera\"] = df_all['Shucked Weight'] - df_all['Viscera Weight']\ndf_all['Length^2'] = df_all['Length'] ** 2\ndf_all['Diameter^2'] = df_all['Diameter'] ** 2\ndf_all['Log Weight'] = np.log(df_all['Weight'] + 1) \ndf_all['Length Bins'] = pd.cut(df_all['Length'], bins=4, labels=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T06:12:18.081391Z","iopub.execute_input":"2023-09-21T06:12:18.081960Z","iopub.status.idle":"2023-09-21T06:12:18.108433Z","shell.execute_reply.started":"2023-09-21T06:12:18.081926Z","shell.execute_reply":"2023-09-21T06:12:18.107204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"background-color:#C0FFFF\"> 위 피처 전부 추가 </span>","metadata":{}},{"cell_type":"code","source":"train = df_all[df_all['Data Type'] != 1]\ntrain.reset_index(drop=True, inplace=True)\n\ny_train = train[\"Age\"].astype(int)\nx_train = train.drop(columns=[\"Age\", \"Data Type\"], axis=1)\n\nx_test = df_all[df_all[\"Data Type\"] == 1]\nx_test.reset_index(drop=True, inplace=True)\nx_test.drop(columns=[\"Age\", \"Data Type\"], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T06:12:18.282436Z","iopub.execute_input":"2023-09-21T06:12:18.282758Z","iopub.status.idle":"2023-09-21T06:12:18.358462Z","shell.execute_reply.started":"2023-09-21T06:12:18.282733Z","shell.execute_reply":"2023-09-21T06:12:18.357308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"background-color:#C0FFFF\"> train test 분리 </span>","metadata":{}},{"cell_type":"markdown","source":"## Model with Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Training\npreds_lgb_fe, models_lgb_fe, oof_lgb_fe, imp_lgb_fe = LightGBM(x_train, y_train, x_test, lgb_params)\n\n# MAE for LightGBM\noof_lgb_round_fe = np.zeros(len(oof_lgb_fe), dtype=int)\nfor i in range(len(oof_lgb_fe)):\n    oof_lgb_round_fe[i] = int((oof_lgb_fe[i] * 2 + 1) // 2)\n\nprint(\"MAE(int):\", \"{:.4f}\".format(mean_absolute_error(y_train, oof_lgb_round_fe)))\nprint(\"MAE(float):\", \"{:.4f}\".format(mean_absolute_error(y_train, oof_lgb_fe)))\n\n# visualization of predictions by test-data\nmean_preds_lgb_fe = np.mean(preds_lgb_fe, axis=0)\nmean_preds_lgb_round_fe = np.zeros(len(mean_preds_lgb_fe), dtype=int)\nfor i in range(len(mean_preds_lgb_round_fe)):\n    mean_preds_lgb_round_fe[i] = int((mean_preds_lgb_fe[i] * 2 + 1) // 2)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T06:12:18.678404Z","iopub.execute_input":"2023-09-21T06:12:18.678933Z","iopub.status.idle":"2023-09-21T06:15:45.243991Z","shell.execute_reply.started":"2023-09-21T06:12:18.678897Z","shell.execute_reply":"2023-09-21T06:15:45.243305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"background-color:#C0FFFF\"> 피처 엔지니어링 후의 MAE값이 유의미하게 줄어들었다.  \nMAE 값을 더 줄이기 위하여 앙상블 학습을 사용하면 더 낮은 MAE 값을 기대해볼 수 있을 것 같다.</span>","metadata":{}},{"cell_type":"markdown","source":"***\n\n<BR>\n    \n    \n<div style=\"text-align: center;\">\n   <span style=\"font-size: 4.5em; font-weight: bold; font-family: Arial;\">THANK YOU!</span>\n</div>\n\n<div style=\"text-align: center;\">\n    <span style=\"font-size: 5em;\">✔️</span>\n</div>\n\n<br>\n\n<div style=\"text-align: center;\">\n   <span style=\"font-size: 1.4em; font-weight: bold; font-family: Arial; max-width:1200px; display: inline-block;\">\n       These features helped me achieved reduced error rate and better leaderboard ranking. If you also found them helpful, please provide an upvote!\n\n   </span>\n</div>\n\n<br>\n\n<br>\n\n<div style=\"text-align: center;\">\n   <span style=\"font-size: 1.2em; font-weight: bold;font-family: Arial;\">@Gaurav Pandey</span>\n</div>","metadata":{}},{"cell_type":"code","source":"def opt_me():\n    train = df_all[df_all['Data Type'] != 1]\n    train.reset_index(drop=True, inplace=True)\n\n    y_train = train[\"Age\"].astype(int)\n    x_train = train.drop(columns=[\"Age\", \"Data Type\"], axis=1)\n\n    x_test = df_all[df_all[\"Data Type\"] == 1]\n    x_test.reset_index(drop=True, inplace=True)\n    x_test.drop(columns=[\"Age\", \"Data Type\"], inplace=True)\n    \n    # Training\n    preds_lgb_fe, models_lgb_fe, oof_lgb_fe, imp_lgb_fe = LightGBM(x_train, y_train, x_test, lgb_params)\n\n    # MAE for LightGBM\n    oof_lgb_round_fe = np.zeros(len(oof_lgb_fe), dtype=int)\n    for i in range(len(oof_lgb_fe)):\n        oof_lgb_round_fe[i] = int((oof_lgb_fe[i] * 2 + 1) // 2)\n\n    print(\"MAE(int):\", \"{:.4f}\".format(mean_absolute_error(y_train, oof_lgb_round_fe)))\n    print(\"MAE(float):\", \"{:.4f}\".format(mean_absolute_error(y_train, oof_lgb_fe)))\n\n    # visualization of predictions by test-data\n    mean_preds_lgb_fe = np.mean(preds_lgb_fe, axis=0)\n    mean_preds_lgb_round_fe = np.zeros(len(mean_preds_lgb_fe), dtype=int)\n    for i in range(len(mean_preds_lgb_round_fe)):\n        mean_preds_lgb_round_fe[i] = int((mean_preds_lgb_fe[i] * 2 + 1) // 2)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T06:16:59.676354Z","iopub.execute_input":"2023-09-21T06:16:59.677523Z","iopub.status.idle":"2023-09-21T06:16:59.686494Z","shell.execute_reply.started":"2023-09-21T06:16:59.677461Z","shell.execute_reply":"2023-09-21T06:16:59.685216Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all.drop(['Length Bins'], axis=1, inplace=True)\nopt_me()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T06:17:34.204594Z","iopub.execute_input":"2023-09-21T06:17:34.204932Z","iopub.status.idle":"2023-09-21T06:20:52.976775Z","shell.execute_reply.started":"2023-09-21T06:17:34.204906Z","shell.execute_reply":"2023-09-21T06:20:52.975857Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"MAE(int): 1.3387\nMAE(float): 1.3555","metadata":{"execution":{"iopub.status.busy":"2023-09-21T06:24:09.302566Z","iopub.execute_input":"2023-09-21T06:24:09.303002Z","iopub.status.idle":"2023-09-21T06:24:09.309145Z","shell.execute_reply.started":"2023-09-21T06:24:09.302965Z","shell.execute_reply":"2023-09-21T06:24:09.307691Z"}}},{"cell_type":"code","source":"df_all['Sex'].unique()\n\ndf_all['Sex_0'] = (df_all['Sex'] == 0).astype(int)\ndf_all['Sex_1'] = (df_all['Sex'] == 1).astype(int)\ndf_all['Sex_2'] = (df_all['Sex'] == 2).astype(int)\n\ndf_all.drop(['Sex'], axis=1, inplace=True)\n\nopt_me()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T06:25:40.899584Z","iopub.execute_input":"2023-09-21T06:25:40.899953Z","iopub.status.idle":"2023-09-21T06:29:01.233270Z","shell.execute_reply.started":"2023-09-21T06:25:40.899925Z","shell.execute_reply":"2023-09-21T06:29:01.232661Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"MAE(int): 1.3383\nMAE(float): 1.3548","metadata":{}},{"cell_type":"markdown","source":"<span style=\"background-color:#C0FFFF\"> 성별을 one-hot encoding하고 importance가 낮은 피처인 lengthbins피처를 삭제함으로써 살짝 더 나은 정도의 MAE를 내 보았다. </span>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}