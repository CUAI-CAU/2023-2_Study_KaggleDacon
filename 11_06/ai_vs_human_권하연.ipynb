{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc2fc0bf",
   "metadata": {},
   "source": [
    "!pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b813e7a1",
   "metadata": {},
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78f3504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# %matplotlib inline\n",
    "\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "plt.rc('axes', unicode_minus=False)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import FunnelTokenizerFast, FunnelModel\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from argparse import ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a531e0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kosroberta_pwNone'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#파서 만들기\n",
    "parser = ArgumentParser(description=\"baseline\")\n",
    "#인자추가하기\n",
    "\n",
    "#사전학습 모델\n",
    "parser.add_argument('--text_pretrained_model', default=\"kosroberta\", type=str)\n",
    "parser.add_argument('--truncation_side', default='right', type=str)\n",
    "parser.add_argument('--pos_weight', default=None, type=int)\n",
    "#옵티마이저\n",
    "parser.add_argument('--optimizer', default=\"adamw\", type=str)\n",
    "#학습률\n",
    "parser.add_argument('--learning_rate', default=0.00003, type=float)\n",
    "parser.add_argument('--scheduler', default=\"none\", type=str)\n",
    "parser.add_argument('--batch_size', default=64, type=int)\n",
    "parser.add_argument('--epochs', default=10, type=int)\n",
    "parser.add_argument('--cv', default=5, type=int)\n",
    "parser.add_argument('--seed', default=826, type=int)\n",
    "parser.add_argument('--mixed_precision', default=16, type=int)\n",
    "parser.add_argument('--device', default=0, type=int)\n",
    "parser.add_argument('--num_workers', default=0, type=int)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "#각각의 변수는 파서의 인자에서 가져올거다\n",
    "BATCH_SIZE = args.batch_size\n",
    "EPOCHS = args.epochs\n",
    "CV = args.cv\n",
    "SEED = args.seed\n",
    "\n",
    "#시드세팅\n",
    "def set_seeds(seed=SEED):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    pl.seed_everything(SEED)\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "idx = f\"{args.text_pretrained_model}_pw{args.pos_weight}\"\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb19c6f8",
   "metadata": {},
   "source": [
    "- argparse :: 프로그램에 필요한 인자를 사용자 친화적인 명령행 인터페이스로 쉽게 작성하도록 돕는 라이브러리. \n",
    "  - 즉, command 창에서 프로그램 내의 인자를 조절하게끔 도와줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a4961d",
   "metadata": {},
   "source": [
    "- 흐름은 다음과 같다\n",
    "\n",
    "##main.py \n",
    "\n",
    "import argparse\n",
    "\n",
    "#파서 만들기</br>\n",
    "parser = argparse.ArgumentParser(description='Argparse example')\n",
    "\n",
    "#인자 추가하기</br>\n",
    "parser.add_argument('--learning_rate', '-lr', type=float, default=0.001, help='learning rate')</br>\n",
    "parser.add_argument('--mode', type=str, defualt='train', choices=['train', 'test'])</br>\n",
    "parser.add_argument('--no_gpu', action='store_true')</br>\n",
    "parser.add_argument('--epochs', type=int, required=True, help='number of epochs')</br>\n",
    "\n",
    "#내가 쓴 인자 저장</br>\n",
    "args = parser.parse_args()\n",
    "\n",
    "#인자 사용</br>\n",
    "lr = args.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d5c1e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.text_pretrained_model == \"kosroberta\":\n",
    "    text_pretrained_model = \"jhgan/ko-sroberta-multitask\"\n",
    "    latent_dim= 384 #* 2\n",
    "if args.text_pretrained_model == \"bert-kor-base\":\n",
    "    text_pretrained_model = \"kykim/bert-kor-base\"\n",
    "    latent_dim= 384 #* 2\n",
    "if args.text_pretrained_model == \"funnel-kor-base\":\n",
    "    text_pretrained_model = \"kykim/funnel-kor-base\"\n",
    "    latent_dim= 384 #* 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0868fa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 5), (1100, 4))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\").drop(columns=[\"id\"])\n",
    "test_df = pd.read_csv(\"test.csv\").drop(columns=[\"id\"])\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b822b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence3</th>\n",
       "      <th>sentence4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>직원들 마음에 들지 않는다는 것은 알겠지만, 가지 말아야 할까? 인터넷에서 싸게 살...</td>\n",
       "      <td>직원들 진짜 싸가지 없어요 ㅋㅋㅋㅋ 가지 마숑  인터넷이 더 싼거 알면서도 이것저것...</td>\n",
       "      <td>직원들 정말 싸가지 없네요 ㅋㅋㅋㅋ 인터넷에서 더 싸게 구입할 수 있다는 걸 알면서...</td>\n",
       "      <td>직원들의 태도가 정말 별로였어요 ㅋㅋㅋㅋ 가볼만한 가게라는 소문을 듣고 인터넷으로 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>분위기 최고! 2층 창문이 넓어서 공기가 통하는 느낌이에요. 조명도 멋지고 음료와 ...</td>\n",
       "      <td>분위기가 너무 좋아요! 2층 창문이 넓어서 쾌적한 느낌이에요. 조명도 아름답고 음료...</td>\n",
       "      <td>분위기가 짱!! 2층 창문이 커서 탁 트여있는 느낌이에요 ㅎㅎ 조명도 예쁘고 음료랑...</td>\n",
       "      <td>분위기가 너무 좋아요! 2층 창문이 크고 넓어서 탁 트여있는 느낌이에요. 조명도 예...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>일단, 장사가 잘 되길 바라는 마음에서 별 다섯 개 드립니다. 간도 딱 맞았고, 저...</td>\n",
       "      <td>일단 장사가 잘되길 바라는 마음에서 별5개 드립니다 간도 맞았고 매운걸 좋아하는 입...</td>\n",
       "      <td>일단 저는 장사가 잘되기를 바라는 마음에서 별 다섯 개를 주고 싶어요. 맛도 딱 맞...</td>\n",
       "      <td>먼저, 칭찬과 응원의 의미로 별 다섯 개를 주고 싶습니다. 간도 딱 맞고, 저는 매...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1편의 독특함 때문에 살짝 뒤로 밀린 느낌이 있지만, 여전히 재미있어요. 게임 시스...</td>\n",
       "      <td>1편의 신선함에 비해 약간 빛이 바래 보이지만, 여전히 재미있게 즐길 수 있어요. ...</td>\n",
       "      <td>1편의 독특함 때문에 약간의 비교가 불가피하지만, 이 게임은 여전히 흥미로워요. 시...</td>\n",
       "      <td>1편이 워낙 참신했던 탓에 좀 묻힌 감이 있긴 하지만 재미는 여전합니다. 시스템도 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>빵점 주고 싶은걸 간신히 참았다...이런건 사상 유래가 없는,조지 루카스 영감의 스...</td>\n",
       "      <td>빵점을 주고 싶지만 참아냈습니다... 이 영화는 사상 유래가 없는 것 같아요. 조지...</td>\n",
       "      <td>빵점 주고 싶을 정도로 엄청 실망했어요... 이 영화는 별들의 전쟁처럼 역사적인 작...</td>\n",
       "      <td>빵점을 주고 싶었는데 참았어요... 이런 영화는 전례가 없는데, 조지 루카스의 스타...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  직원들 마음에 들지 않는다는 것은 알겠지만, 가지 말아야 할까? 인터넷에서 싸게 살...   \n",
       "1  분위기 최고! 2층 창문이 넓어서 공기가 통하는 느낌이에요. 조명도 멋지고 음료와 ...   \n",
       "2  일단, 장사가 잘 되길 바라는 마음에서 별 다섯 개 드립니다. 간도 딱 맞았고, 저...   \n",
       "3  1편의 독특함 때문에 살짝 뒤로 밀린 느낌이 있지만, 여전히 재미있어요. 게임 시스...   \n",
       "4  빵점 주고 싶은걸 간신히 참았다...이런건 사상 유래가 없는,조지 루카스 영감의 스...   \n",
       "\n",
       "                                           sentence2  \\\n",
       "0  직원들 진짜 싸가지 없어요 ㅋㅋㅋㅋ 가지 마숑  인터넷이 더 싼거 알면서도 이것저것...   \n",
       "1  분위기가 너무 좋아요! 2층 창문이 넓어서 쾌적한 느낌이에요. 조명도 아름답고 음료...   \n",
       "2  일단 장사가 잘되길 바라는 마음에서 별5개 드립니다 간도 맞았고 매운걸 좋아하는 입...   \n",
       "3  1편의 신선함에 비해 약간 빛이 바래 보이지만, 여전히 재미있게 즐길 수 있어요. ...   \n",
       "4  빵점을 주고 싶지만 참아냈습니다... 이 영화는 사상 유래가 없는 것 같아요. 조지...   \n",
       "\n",
       "                                           sentence3  \\\n",
       "0  직원들 정말 싸가지 없네요 ㅋㅋㅋㅋ 인터넷에서 더 싸게 구입할 수 있다는 걸 알면서...   \n",
       "1  분위기가 짱!! 2층 창문이 커서 탁 트여있는 느낌이에요 ㅎㅎ 조명도 예쁘고 음료랑...   \n",
       "2  일단 저는 장사가 잘되기를 바라는 마음에서 별 다섯 개를 주고 싶어요. 맛도 딱 맞...   \n",
       "3  1편의 독특함 때문에 약간의 비교가 불가피하지만, 이 게임은 여전히 흥미로워요. 시...   \n",
       "4  빵점 주고 싶을 정도로 엄청 실망했어요... 이 영화는 별들의 전쟁처럼 역사적인 작...   \n",
       "\n",
       "                                           sentence4  label  \n",
       "0  직원들의 태도가 정말 별로였어요 ㅋㅋㅋㅋ 가볼만한 가게라는 소문을 듣고 인터넷으로 ...      2  \n",
       "1  분위기가 너무 좋아요! 2층 창문이 크고 넓어서 탁 트여있는 느낌이에요. 조명도 예...      3  \n",
       "2  먼저, 칭찬과 응원의 의미로 별 다섯 개를 주고 싶습니다. 간도 딱 맞고, 저는 매...      2  \n",
       "3  1편이 워낙 참신했던 탓에 좀 묻힌 감이 있긴 하지만 재미는 여전합니다. 시스템도 ...      4  \n",
       "4  빵점을 주고 싶었는데 참았어요... 이런 영화는 전례가 없는데, 조지 루카스의 스타...      1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "#sentence는 각각 리뷰 텍스트고 라벨은 사람이 작성한 리뷰의 라벨이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c9e8736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_true = []\n",
    "train_false = []\n",
    "#리뷰를 사람이 썼는지 기계가 썼는지 0과 1로만 구분한다. 사람이 썼으면 1. 기계가 썼으면0이다\n",
    "for i, v in enumerate(train_df[\"label\"]):\n",
    "    for j in range(1, 5):\n",
    "        if v==j:\n",
    "            train_true.append(train_df.iat[i, j-1])\n",
    "        else:\n",
    "            train_false.append(train_df.iat[i, j-1])\n",
    "            \n",
    "train_df_true = pd.DataFrame(train_true, columns=[\"text\"])\n",
    "train_df_false = pd.DataFrame(train_false, columns=[\"text\"])\n",
    "train_df_true[\"label\"] = 1\n",
    "train_df_false[\"label\"] = 0\n",
    "\n",
    "train_df = pd.concat([train_df_true, train_df_false]).reset_index(drop=True)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cbbfb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    150\n",
       "1     50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7e7e8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>직원들 진짜 싸가지 없어요 ㅋㅋㅋㅋ 가지 마숑  인터넷이 더 싼거 알면서도 이것저것...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>분위기가 짱!! 2층 창문이 커서 탁 트여있는 느낌이에요 ㅎㅎ 조명도 예쁘고 음료랑...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>일단 장사가 잘되길 바라는 마음에서 별5개 드립니다 간도 맞았고 매운걸 좋아하는 입...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1편이 워낙 참신했던 탓에 좀 묻힌 감이 있긴 하지만 재미는 여전합니다. 시스템도 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>빵점 주고 싶은걸 간신히 참았다...이런건 사상 유래가 없는,조지 루카스 영감의 스...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  직원들 진짜 싸가지 없어요 ㅋㅋㅋㅋ 가지 마숑  인터넷이 더 싼거 알면서도 이것저것...      1\n",
       "1  분위기가 짱!! 2층 창문이 커서 탁 트여있는 느낌이에요 ㅎㅎ 조명도 예쁘고 음료랑...      1\n",
       "2  일단 장사가 잘되길 바라는 마음에서 별5개 드립니다 간도 맞았고 매운걸 좋아하는 입...      1\n",
       "3  1편이 워낙 참신했던 탓에 좀 묻힌 감이 있긴 하지만 재미는 여전합니다. 시스템도 ...      1\n",
       "4  빵점 주고 싶은걸 간신히 참았다...이런건 사상 유래가 없는,조지 루카스 영감의 스...      1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a37ef1",
   "metadata": {},
   "source": [
    "- ID 변수를 기준으로 원래 데이터셋에 있던 여러개의 칼럼 이름을 'variable' 칼럼에 위에서 아래로 길게 쌓아놓고,\n",
    "- 'value' 칼럼에 ID와 variable에 해당하는 값을 넣어주는 식으로 데이터를 재구조화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4a3a403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4400, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df.reset_index()\n",
    "#데이터 재구조화\n",
    "test_df = pd.melt(test_df, id_vars='index', var_name=\"sentence\", value_name=\"text\")\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0916b947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sentence1</td>\n",
       "      <td>배송은 정말 빨랐어요! 집에서 속옷이 불편한데 입기 싫고, 안 입으면 민망해서 구매...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sentence1</td>\n",
       "      <td>하.. 원래도 비쌋는데 가격도 더ㅠ올라가고  품질은 더 떨어졌어요..   김밥에 참...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sentence1</td>\n",
       "      <td>평일 저녁에 방문했을 때, 서비스가 좋지 않았습니다. 음료를 준비하는 듯 보여 기다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>sentence1</td>\n",
       "      <td>직원들의 친절도가 좋지 않았고, 손님이 오셨음에도 불구하고 무시하는 태도를 보여서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sentence1</td>\n",
       "      <td>갈비를 주문했음에도 다른 메뉴가 나왔어요. 그런데 고기의 형태가 기대와 달라 실망스...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   sentence                                               text\n",
       "0      0  sentence1  배송은 정말 빨랐어요! 집에서 속옷이 불편한데 입기 싫고, 안 입으면 민망해서 구매...\n",
       "1      1  sentence1  하.. 원래도 비쌋는데 가격도 더ㅠ올라가고  품질은 더 떨어졌어요..   김밥에 참...\n",
       "2      2  sentence1  평일 저녁에 방문했을 때, 서비스가 좋지 않았습니다. 음료를 준비하는 듯 보여 기다...\n",
       "3      3  sentence1  직원들의 친절도가 좋지 않았고, 손님이 오셨음에도 불구하고 무시하는 태도를 보여서 ...\n",
       "4      4  sentence1  갈비를 주문했음에도 다른 메뉴가 나왔어요. 그런데 고기의 형태가 기대와 달라 실망스..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c733d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200,), (200,), (4400,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_df[\"text\"].values\n",
    "y = train_df[\"label\"].values\n",
    "X_test = test_df[\"text\"].values\n",
    "\n",
    "X.shape, y.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a25b47",
   "metadata": {},
   "source": [
    "## data loader\n",
    " #### FunnelTokenizerFast\n",
    " - Hugging Face Transformers 라이브러리에서 제공하는 토큰화 도구\n",
    " - 아래 질문을 중심으로 모델을 디자인했다.\n",
    "  - 의미 벡터를 잘 압축해서 더 효과적인 모델을 일반적으로 적용가능하게 만들 수 있을까?\n",
    "  - 어떻게 사전훈련된 모델의 의미들을 잘 보존할 수 있을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eff88710",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sentence, label):\n",
    "        self.sentence = sentence\n",
    "        self.label = label\n",
    "        if args.text_pretrained_model == \"funnel-kor-base\":\n",
    "            self.tokenizer = FunnelTokenizerFast.from_pretrained(text_pretrained_model)\n",
    "        else:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(text_pretrained_model)\n",
    "        if args.truncation_side == \"left\":\n",
    "            self.tokenizer.truncation_side = 'left'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentence)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentence[idx]\n",
    "\n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "        \n",
    "        input_ids = encoded[\"input_ids\"][0]\n",
    "        token_type_ids = encoded[\"token_type_ids\"][0]\n",
    "        attention_masks = encoded[\"attention_mask\"][0]\n",
    "        \n",
    "        if self.label is not None:\n",
    "            label = self.label[idx]\n",
    "            return [input_ids, token_type_ids, attention_masks], label\n",
    "        else:\n",
    "            return [input_ids, token_type_ids, attention_masks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6de4282",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6b2606df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwiGLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x, gate = x.chunk(2, dim=-1)\n",
    "        return F.silu(gate) * x\n",
    "#모델 생성\n",
    "class TextModel(nn.Module):\n",
    "    def __init__(self, latent_dim=latent_dim):\n",
    "        super().__init__()\n",
    "        if args.text_pretrained_model == \"funnel-kor-base\":\n",
    "            self.txt_model = FunnelModel.from_pretrained(text_pretrained_model)\n",
    "        else:\n",
    "            self.txt_model = AutoModel.from_pretrained(text_pretrained_model)\n",
    "        self.classifier = nn.Sequential(\n",
    "            SwiGLU(),\n",
    "            nn.Linear(latent_dim, 1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_ids = x[0]\n",
    "        token_type_ids = x[1]\n",
    "        attention_mask = x[2]\n",
    "        \n",
    "        txt_side = self.txt_model(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "        \n",
    "        txt_feature = txt_side.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        output = self.classifier(txt_feature)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "43c57335",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(pl.LightningModule):\n",
    "    #문자 분류기\n",
    "    def __init__(self, backbone, args):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        if args.pos_weight != None:\n",
    "            self.pos_weight = torch.tensor(args.pos_weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        predictions = self.backbone(x)\n",
    "        return predictions\n",
    "\n",
    "    def step(self, batch):\n",
    "        x, y = batch\n",
    "        y_hat = self.backbone(x)\n",
    "        if args.pos_weight != None:\n",
    "            loss = nn.BCEWithLogitsLoss(pos_weight=self.pos_weight)(y_hat.squeeze(), y.float())\n",
    "        else:\n",
    "            loss = nn.BCEWithLogitsLoss()(y_hat.squeeze(), y.float())\n",
    "        return loss, y, y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, y, y_hat = self.step(batch)\n",
    "        predictions = (y_hat > 0).float()\n",
    "        acc = (predictions.squeeze() == y).float().mean()\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, y, y_hat = self.step(batch)\n",
    "        predictions = (y_hat > 0).float()\n",
    "        acc = (predictions.squeeze() == y).float().mean()\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, y, y_hat = self.step(batch)\n",
    "        predictions = (y_hat > 0).float()\n",
    "        acc = (predictions.squeeze() == y).float().mean()\n",
    "        self.log(\"test_acc\", acc)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        y_hat = self.backbone(batch)\n",
    "        return y_hat\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if args.optimizer == \"sgd\":\n",
    "            optimizer = torch.optim.SGD(self.parameters(), lr=args.learning_rate, momentum=0.9)\n",
    "        if args.optimizer == \"adam\":\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=args.learning_rate)\n",
    "        if args.optimizer == \"adamw\":\n",
    "            optimizer = torch.optim.AdamW(self.parameters(), lr=args.learning_rate)\n",
    "        \n",
    "        if args.scheduler == \"none\":\n",
    "            return optimizer\n",
    "        if args.scheduler == \"step\":\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "                optimizer=optimizer,\n",
    "                step_size=2,\n",
    "                gamma=0.9,\n",
    "            )\n",
    "            return [optimizer], [scheduler]\n",
    "        if args.scheduler == \"cosine\":\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer=optimizer,\n",
    "                T_max=EPOCHS,\n",
    "                eta_min=1e-5,\n",
    "            )\n",
    "            return [optimizer], [scheduler]\n",
    "        if args.scheduler == \"onecyclelr\":\n",
    "            scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "                optimizer=optimizer,\n",
    "                max_lr=args.learning_rate,\n",
    "                epochs=EPOCHS,\n",
    "                steps_per_epoch=int(len(train_index) / BATCH_SIZE),\n",
    "                pct_start=0.1,\n",
    "            )\n",
    "            return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1066b09b",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7484842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead6a91bcb6643b1a977ca0e68924f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/744 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba889fbf0554595977a83f377bf81e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.backends' has no attribute 'mps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 37\u001b[0m\n\u001b[0;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m TextClassifier(TextModel(), args)\n\u001b[0;32m     30\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     31\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     32\u001b[0m         dirpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved/\u001b[39m\u001b[38;5;124m\"\u001b[39m, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     33\u001b[0m         monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m     ),\n\u001b[0;32m     35\u001b[0m ]\n\u001b[1;32m---> 37\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmixed_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model, train_dataloader, val_dataloader)\n\u001b[0;32m     45\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pyTest\\lib\\site-packages\\pytorch_lightning\\utilities\\argparse.py:70\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pyTest\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:402\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;66;03m# init connectors\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector \u001b[38;5;241m=\u001b[39m _DataConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 402\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerator_connector \u001b[38;5;241m=\u001b[39m \u001b[43m_AcceleratorConnector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync_batchnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync_batchnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbenchmark\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbenchmark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_distributed_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_distributed_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplugins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector \u001b[38;5;241m=\u001b[39m _LoggerConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_connector \u001b[38;5;241m=\u001b[39m _CallbackConnector(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pyTest\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:139\u001b[0m, in \u001b[0;36m_AcceleratorConnector.__init__\u001b[1;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, sync_batchnorm, benchmark, use_distributed_sampler, deterministic)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layer_sync: Optional[LayerSync] \u001b[38;5;241m=\u001b[39m TorchSyncBatchNorm() \u001b[38;5;28;01mif\u001b[39;00m sync_batchnorm \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_io: Optional[CheckpointIO] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_config_and_set_final_flags\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplugins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync_batchnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync_batchnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# 2. Instantiate Accelerator\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# handle `auto`, `None` and `gpu`\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerator_flag \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pyTest\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:229\u001b[0m, in \u001b[0;36m_AcceleratorConnector._check_config_and_set_final_flags\u001b[1;34m(self, strategy, accelerator, precision, plugins, sync_batchnorm)\u001b[0m\n\u001b[0;32m    227\u001b[0m is_deepspeed_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(strategy, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepspeed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m strategy\n\u001b[0;32m    228\u001b[0m is_parallel_strategy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(strategy, ParallelStrategy) \u001b[38;5;129;01mor\u001b[39;00m is_ddp_str \u001b[38;5;129;01mor\u001b[39;00m is_deepspeed_str\n\u001b[1;32m--> 229\u001b[0m is_mps_accelerator \u001b[38;5;241m=\u001b[39m \u001b[43mMPSAccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    230\u001b[0m     accelerator \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(accelerator, MPSAccelerator)\n\u001b[0;32m    231\u001b[0m )\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mps_accelerator \u001b[38;5;129;01mand\u001b[39;00m is_parallel_strategy:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou set `strategy=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` but strategies from the DDP family are not supported on the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m MPS accelerator. Either explicitly set `accelerator=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` or change the strategy.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pyTest\\lib\\site-packages\\pytorch_lightning\\accelerators\\mps.py:71\u001b[0m, in \u001b[0;36mMPSAccelerator.is_available\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_available\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124;03m\"\"\"MPS is only available on a machine with the ARM-based Apple Silicon processors.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MPSAccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pyTest\\lib\\site-packages\\lightning_fabric\\accelerators\\mps.py:66\u001b[0m, in \u001b[0;36mMPSAccelerator.is_available\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_available\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;124;03m\"\"\"MPS is only available on a machine with the ARM-based Apple Silicon processors.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmps\u001b[49m\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;129;01mand\u001b[39;00m platform\u001b[38;5;241m.\u001b[39mprocessor() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marm64\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.backends' has no attribute 'mps'"
     ]
    }
   ],
   "source": [
    "## preprocessing.py\n",
    "\n",
    "val_ac\n",
    "c_list = []\n",
    "preds_list = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=CV, shuffle=True, random_state=SEED)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "\n",
    "    X_train = X[train_index]\n",
    "    X_val = X[val_index]\n",
    "\n",
    "    y_train = y[train_index]\n",
    "    y_val = y[val_index]\n",
    "\n",
    "## data_loaders.py\n",
    "\n",
    "    train_ds = TextDataset(X_train, y_train)\n",
    "    val_ds = TextDataset(X_val, y_val)\n",
    "    test_ds = TextDataset(X_test, None)\n",
    "\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=args.num_workers)\n",
    "    val_dataloader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=args.num_workers)\n",
    "    test_dataloader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=args.num_workers)\n",
    "\n",
    "## train.py\n",
    "\n",
    "    model = TextClassifier(TextModel(), args)\n",
    "\n",
    "    callbacks = [\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            dirpath=\"saved/\", filename=f\"{idx}_{i}\",\n",
    "            monitor=\"val_acc\", mode=\"max\"\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=EPOCHS, accelerator=\"auto\", callbacks=callbacks,\n",
    "        precision=args.mixed_precision,\n",
    "        devices=[args.device]\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_dataloader, val_dataloader)\n",
    "    \n",
    "    ckpt = torch.load(f\"saved/{idx}_{i}.ckpt\")\n",
    "    model.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "## test.py\n",
    "\n",
    "    eval_dict = trainer.validate(model, dataloaders=val_dataloader)[0]\n",
    "    val_acc_list.append(eval_dict[\"val_acc\"])\n",
    "    \n",
    "    y_preds = trainer.predict(model, dataloaders=test_dataloader)\n",
    "    preds_list.append(np.vstack(y_preds))\n",
    "    \n",
    "val_acc_mean = np.mean(val_acc_list)\n",
    "\n",
    "print(f\"val_acc_mean: {val_acc_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a6930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
